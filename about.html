---
layout: default
nav: about
title: "About Us"
---

<!-- =========================== -->
<!-- Research Interests          -->
<!-- =========================== -->
<section class="page-section pDark pdingBtm30">
  <div class="container">
    <div class="heading text-center">
      <h2>Research Interests</h2>
      <p>
        We work on the theory and practice of trustworthy intelligent systems, with a
        particular focus on safety, verification, and real-world deployment.
      </p>
    </div>

    <div class="row">
      <div class="col-md-6">
        <ul class="list-unstyled section-text">
          <li><i class="fa fa-check color"></i> Safety and trustworthiness of AI and Large Language Models</li>
          <li><i class="fa fa-check color"></i> Formal verification of Cyber-Physical Systems (CPS)</li>
          <li><i class="fa fa-check color"></i> Software verification &amp; validation</li>
        </ul>
      </div>
      <div class="col-md-6">
        <ul class="list-unstyled section-text">
          <li><i class="fa fa-check color"></i> Medical AI (Ophthalmology)</li>
          <li><i class="fa fa-check color"></i> Autonomous driving &amp; F1TENTH (RoboRacer)</li>
        </ul>
      </div>
    </div>

    <div class="row mrgn30">
      <div class="col-md-12 text-center">
        <p class="section-text">
          We aim to develop methods that provide <strong>formal guarantees</strong> for systems
          that directly affect human lives, combining rigorous formal methods with
          data-driven learning and practical engineering.
        </p>
      </div>
    </div>
  </div>
</section>

<!-- =========================== -->
<!-- Lab History / Snapshot      -->
<!-- =========================== -->
<section class="page-section">
  <div class="container">
    <div class="heading text-center">
      <h2>Lab Snapshot</h2>
      <p>Key facts about the Cyber Safety Lab since its foundation.</p>
    </div>

    <div class="row text-center">
      <div class="col-sm-3 col-xs-6">
        <h3>2019.08</h3>
        <p>Lab founded at Gyeongsang National University.</p>
      </div>
      <div class="col-sm-3 col-xs-6">
        <h3>4</h3>
        <p>Master’s students graduated.</p>
      </div>
      <div class="col-sm-3 col-xs-6">
        <h3>4</h3>
        <p>Master’s students currently enrolled.</p>
      </div>
      <div class="col-sm-3 col-xs-6">
        <h3>Global</h3>
        <p>Collaborations with UPenn, KAIST, Aalborg University, INRIA/RISA, and more.</p>
      </div>
    </div>
  </div>
</section>

<!-- =========================== -->
<!-- PI Profile (Improved Layout) -->
<!-- =========================== -->
<section class="page-section pDark">
  <div class="container">

    <div class="heading text-center">
      <h2>Principal Investigator</h2>
    </div>

    <div class="row" style="display:flex; align-items:center;">

      <!-- Photo Area -->
      <div class="col-md-4 text-center">
        <p>
          <img class="img-responsive img-thumbnail img-circle"
               src="images/jin-kim.jpg"
               alt="Jin Hyun Kim"
               style="width: 220px; height: 220px; object-fit: cover; margin: 0 auto;">
        </p>
        <h4 style="margin-top:15px;">Jin Hyun Kim</h4>
        <p class="muted" style="margin-bottom:5px;">Associate Professor, AI Information Engineering, GNU</p>
        <p><i class="fa fa-envelope-o"></i> jin.kim@gnu.ac.kr</p>
      </div>

      <!-- Text Area -->
      <div class="col-md-8 pi-profile-text">
        <p>
          I am an associate professor in the Department of AI Information Engineering at
          Gyeongsang National University. I completed my postdoctoral research under the
          supervision of Professor Insup Lee at the PRECISE Lab, University of Pennsylvania.
        </p>

        <p>
          My research interests include software verification and validation, especially for
          cyber-physical systems (CPS), and the safety and trustworthiness of AI in domains
          such as medical AI and autonomous driving. I recently developed
          <strong>Ophtimus</strong> (Ophthalmological Small Language Models), a family of
          domain-specialized ophthalmology LLMs designed to support reliable
          clinical decision-making.
        </p>

        <p>
          I have collaborated with groups at the PRECISE Lab of the University of Pennsylvania,
          KAIST, Aalborg University, and INRIA/RISA, and previously worked with advisors
          including Kim G. Larsen, Axel Legay, and Sungwon Kang.
        </p>
      </div>

    </div>
  </div>
</section>



<!-- =========================== -->
<!-- Latest News                 -->
<!-- =========================== -->
<section class="page-section darkBg">
  <div class="container">
    <div class="heading text-center">
      <h2>Latest News</h2>
      <p>
        Recent achievements and updates from our research group, including newly accepted
        SCI(E) papers in AI Safety, Medical AI, and Cyber-Physical Systems.
      </p>
    </div>

    <div class="row">
      <div class="col-md-10 col-md-offset-1">
        <ul class="section-text">
          <li>
            Soomin Cho, Inhye Kang, and <strong>Jin Hyun Kim</strong>.
            “<em>From timed automata to go: Formally verified code generation and runtime monitoring for cyber-physical systems.</em>”
            <strong>IEEE Access</strong>, 2025. Accepted.
          </li>
          <li>
            <strong>Jin Hyun Kim</strong> et al.
            “<em>Low-cost and fast epiretinal membrane detection and quantification based on SD-OCT.</em>”
            <strong>IEEE Access</strong>, 2025. Accepted.
          </li>
          <li>
            <strong>Jin Hyun Kim</strong> et al.
            “<em>Noise-robust markerless video gait anomaly detection via two-stage acquisition and LSTM autoencoders.</em>”
            <strong>Scientific Reports</strong>, 2025. Accepted.
          </li>
          <li>
            <strong>Jin Hyun Kim</strong> et al.
            “<em>Ophtimus-V2-Tx: A compact domain-specific LLM for ophthalmic diagnosis and treatment planning.</em>”
            <strong>Scientific Reports</strong>, 2025. Accepted.
          </li>
        </ul>

        <p class="section-text">
          More updates coming soon as our group continues advancing AI Safety,
          Medical LLMs, and CPS verification research.
        </p>
      </div>
    </div>
  </div>
</section>
