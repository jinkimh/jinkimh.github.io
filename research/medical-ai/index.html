---
layout: default
nav: projects
title: "Projects – Medical AI & LLM"
---

<!-- =========================== -->
<!-- 1. Projects 페이지 헤더 -->
<!-- =========================== -->
<section id="project" class="page-section section appear clearfix">
  <div class="container">

    <div class="heading text-center">
      <h2>Medical AI & LLM Projects<br>
        <small>의료 인공지능 및 LLM 연구</small>
      </h2>

      <p>
        AiX Lab at Gyeongsang National University leads research in medical AI 
        and ophthalmology-focused large language models that bridge clinical 
        practice and trustworthy AI. Our work spans fundus-based oculomics, 
        visual acuity estimation, video gait analysis, wearable sensing, and 
        domain-specialized LLMs for ophthalmic diagnosis and treatment planning.
        <br><br>

        경상국립대학교 AiX Lab은 임상 현장과 신뢰할 수 있는 AI 기술을 연결하는 
        의료 인공지능 및 안과 특화 대규모 언어 모델(LLM)을 선도적으로 개발하고 있습니다. 
        안저 기반 오큘로믹스(oculomics), 시력 추정, 보행 이상 분석, 웨어러블 기반 생체신호 분석, 
        그리고 안과 진단·치료 계획을 위한 도메인 특화 LLM까지 폭넓은 연구를 수행하고 있습니다.
        <br><br>

        <strong>We developed Korea’s first ophthalmology-specialized xsLM-Ophtimus LLM series 
        (Ophtimus-Base, Ophtimus-1B/3B/8B, Ophtimus-Instruct-8B),</strong> now publicly available at:  
        <a href="https://github.com/jinkimh/jinkimh.github.io" target="_blank">
          github.com/jinkimh/jinkimh.github.io
        </a>.
        <br>
        <strong>저희 연구실은 국내 최초로 안과 의학 지식에 특화된 
        xsLM-Ophtimus 시리즈(Ophtimus-Base, Ophtimus-1B/3B/8B, Ophtimus-Instruct-8B)를 개발하여 공개했습니다.</strong>
      </p>

    </div>

  </div>
</section>


<!-- =========================== -->
<!-- 2. Representative Publications 섹션 -->
<!-- =========================== -->
<section id="projects" class="section section-alt">
  <div class="container">

    <!-- =============================== -->
    <!-- 3. Medical AI / LLM Publications -->
    <!-- =============================== -->
    <h3 style="margin-top:40px;">Representative Medical AI &amp; LLM Publications (reverse chronological)</h3>

    <ul class="section-text" style="margin-top:15px;">

      <!-- 2025 – LLMs -->
      <li>
        <strong>2025 – Ophtimus-V2-Tx: Ophthalmic treatment-planning LLM</strong><br>
        <strong>Kim, Jin Hyun</strong> et al.<br>
        “Ophtimus-V2-Tx: A compact domain-specific LLM for ophthalmic diagnosis and treatment planning.”<br>
        <em>Scientific Reports</em>, 2025. Accepted for publication, 2025.<br>
        &nbsp;&nbsp;→ 안과 진단과 처치 계획을 지원하기 위한 도메인 특화 의료 LLM으로,
        소형(8B급) 구조에서 hallucination 감소와 설명 가능한 임상 추론을 지향하는 모델.
      </li>

      <li>
        <strong>2025 – Ophtimus-LLM: Specialized LLM for ophthalmology</strong><br>
        Seung Ju Baek, Kuk Jin Jang, Sooyong Jang, Hyonyoung Choi, Minwook Kwon,
        Yong Seop Han, Seongjin Lee, <strong>Kim, Jin Hyun</strong>, and Insup Lee.<br>
        “Ophtimus-LLM: Development of a specialized large language model for ophthalmology.”<br>
        In <em>AAAI 2025 Workshop on Generative AI for Health (GenAI4Health)</em>, 2025.<br>
        &nbsp;&nbsp;→ 안과 임상 데이터를 학습한 전문 LLM으로, 안저 소견 기술, 임상 질문응답,
        진단·치료 reasoning을 실험한 초기 버전 모델.
      </li>

      <!-- 2025 – Medical AI models -->
      <li>
        <strong>2025 – Low-cost ERM detection on SD-OCT</strong><br>
        <strong>Kim, Jin Hyun</strong> et al.<br>
        “Low-cost and fast epiretinal membrane detection and quantification based on SD-OCT.”<br>
        <em>IEEE Access</em>, 2025. Accepted for publication, 2025.<br>
        &nbsp;&nbsp;→ 표준 SD-OCT 장비에서 얻은 영상을 이용해 황반부 망막앞막(ERM)을 자동 검출·정량화하는
        경량 딥러닝 파이프라인으로, 임상 현장에서 빠른 스크리닝을 목표로 함.
      </li>

      <li>
        <strong>2025 – Noise-robust markerless gait anomaly detection</strong><br>
        <strong>Kim, Jin Hyun</strong> et al.<br>
        “Noise-robust markerless video gait anomaly detection via two-stage acquisition and LSTM autoencoders.”<br>
        <em>Scientific Reports</em>, 2025. Accepted for publication, 2025.<br>
        &nbsp;&nbsp;→ 마커 없이 촬영한 보행 비디오에서 두 단계 데이터 취득과 LSTM 오토인코더를 통해
        노이즈에 강인한 보행 이상 탐지를 수행하는 모델.
      </li>

      <!-- 2024 -->
      <li>
        <strong>2024 – Fundus-based oculomics for HbA1c</strong><br>
        <strong>Kim, Jin Hyun</strong> et al.<br>
        “Development of oculomics artificial intelligence for cardiovascular risk factors:
        A case study in fundus oculomics for HbA1c assessment and clinically relevant considerations for clinicians.”<br>
        <em>Asia-Pacific Journal of Ophthalmology</em>, 13(4), July 2024.<br>
        &nbsp;&nbsp;→ 안저 영상만으로 당화혈색소(HbA1c) 등 심혈관 위험 인자를 추정하는 oculomics AI를
        구축하고, 임상의 관점에서 해석 시 주의점과 활용 가능성을 논의.
      </li>

      <!-- 2022 -->
      <li>
        <strong>2022 – Visual acuity estimation from fundus images</strong><br>
        <strong>Kim, Jin Hyun</strong> et al.<br>
        “Estimation of best corrected visual acuity based on deep neural network.”<br>
        <em>Scientific Reports</em>, 12(1), October 2022.<br>
        &nbsp;&nbsp;→ 안저 이미지를 입력으로 환자의 최대 교정시력(BCVA)을 추정하는 딥러닝 모델을 제안하여,
        전통적인 시력검사의 보조 도구로서 가능성을 제시.
      </li>

      <li>
        <strong>2022 – Deep learning ensemble for visual acuity measurement</strong><br>
        <strong>Jin Hyun Kim</strong> et al.<br>
        “A deep learning ensemble method to visual acuity measurement using fundus images.”<br>
        <em>Applied Sciences</em>, 12(6), March 2022.<br>
        &nbsp;&nbsp;→ 서로 다른 네트워크 구조를 앙상블해 안저 기반 시력 추정의 정확도와 안정성을
        향상시키는 방법을 제시.
      </li>

      <li>
        <strong>2022 – Asymmetry between right and left fundus images</strong><br>
        <strong>Kim, Jin Hyun</strong> et al.<br>
        “Asymmetry between right and left fundus images identified using convolutional neural networks.”<br>
        <em>Scientific Reports</em>, 12(1), April 2022. Corrigendum noted 2022-10-25.<br>
        &nbsp;&nbsp;→ 양안 안저 영상에서 CNN으로 구조적 비대칭성을 탐지하여, 질환 관련
        비대칭 지표를 정량화하는 연구.
      </li>

      <li>
        <strong>2022 – Smartwatch-based pre-symptomatic COVID-19 detection</strong><br>
        <strong>Jin Hyun Kim</strong> et al.<br>
        “Machine learning-based optimization of pre-symptomatic COVID-19 detection through smartwatch.”<br>
        <em>Scientific Reports</em>, 12(1), May 2022.<br>
        &nbsp;&nbsp;→ 스마트워치 생체 신호를 이용해 증상 발현 전에 COVID-19 감염 가능성을 탐지하는
        머신러닝 기반 모델 및 피처 설계.
      </li>

      <!-- 2021 -->
      <li>
        <strong>2021 – Automated anterior chamber cell analysis</strong><br>
        <strong>Kim, Jin Hyun</strong> et al.<br>
        “Development of fully automated anterior chamber cell analysis based on image software.”<br>
        <em>Scientific Reports</em>, 11(1), May 2021.<br>
        &nbsp;&nbsp;→ 슬릿램프 영상 등에서 전방세포(AC cell)를 자동 계측하는 이미지 기반 분석 소프트웨어를
        개발하여, 안과 염증 평가의 객관화·자동화를 시도.
      </li>

    </ul>

    <div class="text-center" style="margin-top:30px;">
      <a href="/about.html" class="btn btn-primary">
        Learn more about AiX Lab
      </a>
      <a href="/team.html" class="btn btn-primary" style="margin-left:8px;">
        Meet the Team
      </a>
    </div>

  </div>
</section>
